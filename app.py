from flask import Flask, render_template, request, jsonify
import json
import time
import os
import torch
import numpy as np
from Library.TF_IDF import TFIDF  # Tr·ªü l·∫°i import g·ªëc
from helper import load_documents_from_json, relevance_score_tfidf
from Library.rank_net import RankNet

app = Flask(__name__)

# Global variables ƒë·ªÉ l∆∞u model v√† d·ªØ li·ªáu
model = None
documents = []
tfidf_model = None
matrix = []
vocab = []

def initialize_system():
    """Kh·ªüi t·∫°o h·ªá th·ªëng t√¨m ki·∫øm"""
    global model, documents, tfidf_model, matrix, vocab
    
    print("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng...")
    
    try:
        # T·∫£i t√†i li·ªáu - d√πng medium ƒë·ªÉ c√≥ ƒë·ªß vocab
        documents_path = "FetchData/output/cadao_tucngu_medium.json"  # ƒê·ªïi sang medium
        if not os.path.exists(documents_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {documents_path}")
        
        documents = load_documents_from_json(documents_path)
        print(f"ƒê√£ t·∫£i {len(documents)} t√†i li·ªáu")
        
        # Kh·ªüi t·∫°o TF-IDF - T·∫ÆT stopwords ƒë·ªÉ test
        stopword_path = None  # T·∫ÆT stopwords t·∫°m th·ªùi
        print(f"‚ö†Ô∏è  T·∫ÆT stopwords ƒë·ªÉ test (nh∆∞ test_multi_word_query.py c√≥ th·ªÉ ƒëang l√†m)")
        
        tfidf_model = TFIDF(documents, stopword_path=stopword_path)
        matrix = tfidf_model.fit_transform()
        vocab = tfidf_model.get_feature_names()
        print(f"ƒê√£ t·∫°o ma tr·∫≠n TF-IDF v·ªõi {len(vocab)} t·ª´")
        
        # Debug: ki·ªÉm tra vocab c√≥ t·ª´ quan tr·ªçng kh√¥ng
        important_words = ["anh", "em", "qu·∫£", "c√¢y", "ng∆∞·ªùi"]
        print("üîç Ki·ªÉm tra t·ª´ quan tr·ªçng trong vocab:")
        for word in important_words:
            if word in vocab:
                print(f"   ‚úÖ '{word}' c√≥ trong vocab")
            else:
                print(f"   ‚ùå '{word}' KH√îNG c√≥ trong vocab")
        
        print(f"üîç Vocab sample: {vocab[:20]}")  # In 20 t·ª´ ƒë·∫ßu
        
        # Kh·ªüi t·∫°o model RankNet
        model = RankNet(input_size=len(vocab))
        model.eval()  # Ch·∫ø ƒë·ªô ƒë√°nh gi√°
        print("H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
        return True
        
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o h·ªá th·ªëng: {str(e)}")
        return False

def train_model_for_query(query):
    """Hu·∫•n luy·ªán model cho m·ªôt query c·ª• th·ªÉ"""
    global model, documents, matrix, vocab
    
    from itertools import combinations
    import torch.optim as optim
    from torch.utils.data import Dataset, DataLoader
    from main import RankNetDataset
    from helper import ranknet_loss
    
    print(f"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán model cho query: '{query}'")
    
    # T√≠nh ƒëi·ªÉm li√™n quan
    scores = [relevance_score_tfidf(matrix, vocab, query, i) for i in range(len(documents))]
    print(f"ƒêi·ªÉm TF-IDF cho t·ª´ '{query}': {scores}")
    
    # T·∫°o c·∫∑p d·ªØ li·ªáu hu·∫•n luy·ªán
    pairs = []
    for i, j in combinations(range(len(documents)), 2):
        if scores[i] == scores[j]:
            continue
        dij = (matrix[i], matrix[j])
        pij = 1 if scores[i] > scores[j] else 0
        pairs.append((dij, pij))
    
    print(f"S·ªë c·∫∑p t√†i li·ªáu ƒë∆∞·ª£c t·∫°o: {len(pairs)}")
    
    if len(pairs) == 0:
        print("Kh√¥ng c√≥ c·∫∑p d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán!")
        return False
    
    # Hu·∫•n luy·ªán nhanh
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    dataset = RankNetDataset(pairs, matrix)
    dataloader = DataLoader(dataset, batch_size=min(16, len(pairs)), shuffle=True)
    
    print(f"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v·ªõi {len(pairs)} c·∫∑p d·ªØ li·ªáu...")
    
    model.train()
    for epoch in range(200):  # S·ª≠ d·ª•ng 100 epochs nh∆∞ main.py
        total_loss = 0
        for di_vec, dj_vec, pij in dataloader:
            optimizer.zero_grad()
            si = model(di_vec)
            sj = model(dj_vec)
            loss = ranknet_loss(si, sj, pij)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        if epoch % 20 == 0:  # In log m·ªói 20 epochs
            print(f"Epoch {epoch}, Loss: {total_loss / len(dataloader):.4f}")
    
    model.eval()
    print("Hu·∫•n luy·ªán ho√†n t·∫•t!")
    return True

def search_documents(query):
    """T√¨m ki·∫øm v√† x·∫øp h·∫°ng t√†i li·ªáu - Logic ch√≠nh x√°c nh∆∞ main.py"""
    global model, documents, matrix, vocab
    
    start_time = time.time()
    print(f"T√¨m ki·∫øm cho t·ª´ kh√≥a: '{query}'")
    
    # T√≠nh ƒëi·ªÉm li√™n quan TF-IDF tr∆∞·ªõc khi hu·∫•n luy·ªán (ƒë·ªÉ debug)
    scores = [relevance_score_tfidf(matrix, vocab, query.lower(), i) for i in range(len(documents))]
    print(f"ƒêi·ªÉm li√™n quan TF-IDF: {scores}")  # In t·∫•t c·∫£ ƒëi·ªÉm ƒë·ªÉ debug
    
    # Hu·∫•n luy·ªán model cho query n√†y
    training_success = train_model_for_query(query.lower())
    
    if not training_success:
        print("Fallback v·ªÅ TF-IDF v√¨ kh√¥ng c√≥ d·ªØ li·ªáu hu·∫•n luy·ªán")
        # Fallback v·ªÅ TF-IDF n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu hu·∫•n luy·ªán
        results = [(scores[i], documents[i]) for i in range(len(documents)) if scores[i] > 0]
    else:
        print("S·ª≠ d·ª•ng RankNet ƒë·ªÉ t√≠nh ƒëi·ªÉm")
        # B∆∞·ªõc 4: D·ª± ƒëo√°n v√† x·∫øp h·∫°ng - CH√çNH X√ÅC nh∆∞ main.py
        model.eval()
        scores_rank = []
        with torch.no_grad():
            for i in range(len(documents)):
                score = model(torch.tensor(matrix[i], dtype=torch.float32)).item()
                scores_rank.append((score, documents[i]))
        
        # Tr·∫£ v·ªÅ T·∫§T C·∫¢ k·∫øt qu·∫£ nh∆∞ main.py (kh√¥ng l·ªçc)
        results = scores_rank
    
    # S·∫Øp x·∫øp theo ƒëi·ªÉm s·ªë gi·∫£m d·∫ßn - nh∆∞ main.py
    results.sort(key=lambda x: x[0], reverse=True)
    
    # Gi·ªõi h·∫°n k·∫øt qu·∫£ ƒë·ªÉ hi·ªÉn th·ªã web (top 10 thay v√¨ 20)
    results = results[:10]
    
    end_time = time.time()
    search_time = round(end_time - start_time, 3)
    
    print(f"T√¨m th·∫•y {len(results)} k·∫øt qu·∫£ trong {search_time}s")
    print("K·∫øt qu·∫£ x·∫øp h·∫°ng:")
    for score, doc in results[:5]:  # In 5 k·∫øt qu·∫£ ƒë·∫ßu
        print(f"  {score:.4f} - {doc}")
    
    return results, search_time

@app.route('/')
def index():
    """Trang ch·ªß"""
    return render_template('index.html')

@app.route('/search', methods=['POST'])
def search():
    """API t√¨m ki·∫øm"""
    try:
        print("Nh·∫≠n y√™u c·∫ßu t√¨m ki·∫øm...")
        print("D·ªØ li·ªáu y√™u c·∫ßu:", request.get_data(as_text=True))
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({'error': 'Query kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng'}), 400
        
        results, search_time = search_documents(query)
        
        # Format k·∫øt qu·∫£
        formatted_results = [
            {
                'score': score,
                'content': content
            }
            for score, content in results
        ]
        
        return jsonify({
            'results': formatted_results,
            'total_results': len(formatted_results),
            'total_time': search_time,
            'query': query
        })
        
    except Exception as e:
        print(f"L·ªói t√¨m ki·∫øm: {str(e)}")
        return jsonify({'error': 'C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh t√¨m ki·∫øm'}), 500

@app.route('/health')
def health():
    """Ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng"""
    return jsonify({
        'status': 'healthy',
        'documents_loaded': len(documents),
        'vocab_size': len(vocab) if vocab else 0
    })

if __name__ == '__main__':
    print("\n" + "="*50)
    print("üöÄ Kh·ªüi ƒë·ªông server Flask...")
    print("üìç Truy c·∫≠p: http://localhost:5000")
    print("="*50 + "\n")
    
    # Kh·ªüi t·∫°o h·ªá th·ªëng
    if initialize_system():
        app.run(debug=True, host='0.0.0.0', port=5000)
    else:
        print("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o h·ªá th·ªëng!")
        print("üí° Th·ª≠ ch·∫°y app_simple.py ƒë·ªÉ test giao di·ªán:")
        print("   python app_simple.py")
        input("Nh·∫•n Enter ƒë·ªÉ tho√°t...")
