{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6h7KPFJqNMB",
        "outputId": "31cc84a9-e311-4b75-8e52-427a1408bb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-ffb9050d-a787-d844-1573-4371126d4b71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import các thư viện cần sử dụng"
      ],
      "metadata": {
        "id": "yLS4WrSarXBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvi\n",
        "# !pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-GwQPsx2mEg",
        "outputId": "1c6e6feb-308b-4a91-84b2-aba2d1424753"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyvi) (1.6.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.11/dist-packages (from pyvi) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (3.6.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.11)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pyvi import ViTokenizer\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "baNRYvdKrrKf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Định nghĩa class RankNet - kết thừa từ thư viện: torch.nn.Module"
      ],
      "metadata": {
        "id": "i4FErFmyv87U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RankNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1=256, hidden_size2=128, dropout=0.2):\n",
        "        \"\"\"\n",
        "        RankNet với 2 tầng ẩn\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Số features đầu vào\n",
        "            hidden_size1 (int): Số neurons tầng ẩn thứ nhất\n",
        "            hidden_size2 (int): Số neurons tầng ẩn thứ hai\n",
        "            dropout (float): Tỷ lệ dropout để tránh overfitting\n",
        "        \"\"\"\n",
        "        super(RankNet, self).__init__()\n",
        "\n",
        "        # Định nghĩa các tầng\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, 1)  # Output layer cho score\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        # Layer normalization thay vì batch normalization để tránh lỗi khi batch_size=1\n",
        "        self.ln1 = nn.LayerNorm(hidden_size1)\n",
        "        self.ln2 = nn.LayerNorm(hidden_size2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor có shape (batch_size, input_size)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output scores có shape (batch_size, 1)\n",
        "        \"\"\"\n",
        "        # Đảm bảo input là tensor và có đúng kiểu dữ liệu\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "        # Tầng ẩn thứ nhất\n",
        "        x = self.fc1(x)\n",
        "        x = self.ln1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Tầng ẩn thứ hai\n",
        "        x = self.fc2(x)\n",
        "        x = self.ln2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Output layer\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def predict_rank(self, x1, x2):\n",
        "        \"\"\"\n",
        "        So sánh ranking giữa hai samples\n",
        "\n",
        "        Args:\n",
        "            x1, x2 (torch.Tensor): Hai samples cần so sánh\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Xác suất x1 được rank cao hơn x2\n",
        "        \"\"\"\n",
        "        score1 = self.forward(x1)\n",
        "        score2 = self.forward(x2)\n",
        "\n",
        "        # Sử dụng sigmoid để chuyển về xác suất\n",
        "        prob = torch.sigmoid(score1 - score2)\n",
        "        return prob\n"
      ],
      "metadata": {
        "id": "OPdkzRkzwIcW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hàm mất mát"
      ],
      "metadata": {
        "id": "Zkp0aCK-w58i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ranknet_loss(s_i, s_j, P_ij):\n",
        "    diff = s_i - s_j\n",
        "    P_hat = torch.sigmoid(diff)  # Xác suất dự đoán P̂ᵢⱼ\n",
        "    # Thêm epsilon để tránh log(0)\n",
        "    epsilon = 1e-10\n",
        "    loss = -P_ij * torch.log(P_hat + epsilon) - (1 - P_ij) * torch.log(1 - P_hat + epsilon)\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "D3YdLQ86w77_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một số lớp, hàm phụ trợ"
      ],
      "metadata": {
        "id": "c4zlhnATyWha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreparator:\n",
        "    \"\"\"\n",
        "    Class chuyên dụng cho việc chuẩn bị dữ liệu pairwise training\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sentence_model: SentenceTransformer, stopwords_path: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Khởi tạo DataPreparator\n",
        "\n",
        "        Args:\n",
        "            sentence_model: Mô hình sentence transformer\n",
        "            stopwords_path: Đường dẫn file stopwords (optional)\n",
        "        \"\"\"\n",
        "        self.sentence_model = sentence_model\n",
        "        self.stopwords = set()\n",
        "\n",
        "        # Load stopwords nếu có\n",
        "        if stopwords_path and os.path.exists(stopwords_path):\n",
        "            with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
        "                self.stopwords = set(line.strip() for line in f if line.strip())\n",
        "            print(f\"Đã load {len(self.stopwords)} stopwords từ {stopwords_path}\")\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Tiền xử lý văn bản với PyVi\n",
        "\n",
        "        Args:\n",
        "            text: Văn bản cần xử lý\n",
        "\n",
        "        Returns:\n",
        "            str: Văn bản đã được xử lý\n",
        "        \"\"\"\n",
        "        # 1. Chuẩn hóa cơ bản\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)  # loại bỏ dấu câu\n",
        "        text = re.sub(r'\\d+', ' ', text)      # loại bỏ số\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()  # bỏ khoảng trắng thừa\n",
        "\n",
        "        # 2. Tokenize với PyVi\n",
        "        tokenized = ViTokenizer.tokenize(text)\n",
        "\n",
        "        # 3. Tách thành danh sách từ và lọc stopwords\n",
        "        tokens = tokenized.split()\n",
        "        if self.stopwords:\n",
        "            tokens = [token for token in tokens if token not in self.stopwords]\n",
        "\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "\n",
        "    def calculate_relevance_scores(self, query: str, documents: List[Dict],\n",
        "                                relevance_method: str = 'cosine_ranking') -> List[Tuple[int, float, int]]:\n",
        "        \"\"\"\n",
        "        Tính điểm relevance cho tất cả documents với một query\n",
        "        \"\"\"\n",
        "        # Preprocess query\n",
        "        processed_query = self.preprocess_text(query)\n",
        "\n",
        "        # Encode query\n",
        "        query_embedding = self.sentence_model.encode([processed_query])\n",
        "\n",
        "        # Preprocess và encode tất cả documents\n",
        "        doc_texts = []\n",
        "        for doc in documents:\n",
        "            processed_doc = self.preprocess_text(doc['value'])\n",
        "            doc_texts.append(processed_doc)\n",
        "\n",
        "        doc_embeddings = self.sentence_model.encode(doc_texts)\n",
        "\n",
        "        # Tính cosine similarity\n",
        "        similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
        "\n",
        "        # Gán relevance labels - SỬA CHÍNH TẠI ĐÂY\n",
        "        doc_relevances = []\n",
        "\n",
        "        if relevance_method == 'cosine_ranking':\n",
        "            # Sắp xếp theo similarity và gán labels theo ranking\n",
        "            doc_similarities = [(i, sim) for i, sim in enumerate(similarities)]\n",
        "            doc_similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Phân phối relevance tốt hơn\n",
        "            total_docs = len(doc_similarities)\n",
        "            for rank, (doc_idx, similarity) in enumerate(doc_similarities):\n",
        "                if rank < max(1, total_docs // 10):  # Top 10%: Highly relevant\n",
        "                    relevance = 3\n",
        "                elif rank < max(2, total_docs // 5):  # Top 20%: Relevant\n",
        "                    relevance = 2\n",
        "                elif rank < max(3, total_docs // 3):  # Top 33%: Somewhat relevant\n",
        "                    relevance = 1\n",
        "                else:  # Còn lại: Not relevant\n",
        "                    relevance = 0\n",
        "\n",
        "                doc_relevances.append((doc_idx, float(similarity), relevance))\n",
        "\n",
        "        elif relevance_method == 'threshold_based':\n",
        "            # Điều chỉnh threshold cho phù hợp hơn\n",
        "            for doc_idx, similarity in enumerate(similarities):\n",
        "                if similarity >= 0.7:  # Giảm từ 0.8 xuống 0.7\n",
        "                    relevance = 3\n",
        "                elif similarity >= 0.5:  # Giảm từ 0.6 xuống 0.5\n",
        "                    relevance = 2\n",
        "                elif similarity >= 0.3:  # Giảm từ 0.4 xuống 0.3\n",
        "                    relevance = 1\n",
        "                else:\n",
        "                    relevance = 0\n",
        "\n",
        "                doc_relevances.append((doc_idx, float(similarity), relevance))\n",
        "\n",
        "        return doc_relevances\n",
        "\n",
        "    def generate_pairwise_data(self, queries: List[str], documents: List[Dict],\n",
        "                             relevance_method: str = 'cosine_ranking',\n",
        "                             max_pairs_per_query: Optional[int] = None,\n",
        "                             balance_labels: bool = True) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Tạo dữ liệu pairwise training\n",
        "\n",
        "        Args:\n",
        "            queries: Danh sách queries\n",
        "            documents: Danh sách documents\n",
        "            relevance_method: Phương pháp tính relevance\n",
        "            max_pairs_per_query: Giới hạn số cặp per query (optional)\n",
        "            balance_labels: Có cân bằng labels không\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: Danh sách pairwise samples\n",
        "        \"\"\"\n",
        "        print(f\"Bắt đầu tạo dữ liệu pairwise với {len(queries)} queries và {len(documents)} documents\")\n",
        "\n",
        "        all_pairwise_data = []\n",
        "        label_counts = {0.0: 0, 0.5: 0, 1.0: 0}\n",
        "\n",
        "        for query_idx, query in enumerate(tqdm(queries, desc=\"Tạo dữ liệu pairwise\")):\n",
        "            # Tính relevance scores\n",
        "            doc_relevances = self.calculate_relevance_scores(query, documents, relevance_method)\n",
        "\n",
        "            # Tạo tất cả các cặp possible\n",
        "            query_pairs = []\n",
        "\n",
        "            for i in range(len(doc_relevances)):\n",
        "                for j in range(i + 1, len(doc_relevances)):\n",
        "                    doc1_idx, doc1_sim, doc1_rel = doc_relevances[i]\n",
        "                    doc2_idx, doc2_sim, doc2_rel = doc_relevances[j]\n",
        "\n",
        "                    # Xác định label cho cặp\n",
        "                    if doc1_rel > doc2_rel:\n",
        "                        label = 1.0  # Doc1 tốt hơn Doc2\n",
        "                    elif doc1_rel < doc2_rel:\n",
        "                        label = 0.0  # Doc1 kém hơn Doc2\n",
        "                    else:\n",
        "                        label = 0.5  # Bằng nhau\n",
        "\n",
        "                    # Tạo sample\n",
        "                    pairwise_sample = {\n",
        "                        \"query_id\": query_idx,\n",
        "                        \"query\": query,\n",
        "                        \"query_processed\": self.preprocess_text(query),\n",
        "                        \"doc1_id\": documents[doc1_idx]['id'],\n",
        "                        \"doc1_text\": documents[doc1_idx]['value'],\n",
        "                        \"doc1_processed\": self.preprocess_text(documents[doc1_idx]['value']),\n",
        "                        \"doc1_relevance\": doc1_rel,\n",
        "                        \"doc1_similarity\": doc1_sim,\n",
        "                        \"doc2_id\": documents[doc2_idx]['id'],\n",
        "                        \"doc2_text\": documents[doc2_idx]['value'],\n",
        "                        \"doc2_processed\": self.preprocess_text(documents[doc2_idx]['value']),\n",
        "                        \"doc2_relevance\": doc2_rel,\n",
        "                        \"doc2_similarity\": doc2_sim,\n",
        "                        \"label\": label,\n",
        "                        \"relevance_method\": relevance_method\n",
        "                    }\n",
        "\n",
        "                    query_pairs.append(pairwise_sample)\n",
        "                    label_counts[label] += 1\n",
        "\n",
        "            # Giới hạn số cặp per query nếu cần\n",
        "            if max_pairs_per_query and len(query_pairs) > max_pairs_per_query:\n",
        "                # Sampling có cân bằng labels\n",
        "                if balance_labels:\n",
        "                    query_pairs = self._balanced_sampling(query_pairs, max_pairs_per_query)\n",
        "                else:\n",
        "                    query_pairs = query_pairs[:max_pairs_per_query]\n",
        "\n",
        "            all_pairwise_data.extend(query_pairs)\n",
        "\n",
        "        # In thống kê\n",
        "        total_pairs = len(all_pairwise_data)\n",
        "        print(f\"\\nThống kê dữ liệu pairwise:\")\n",
        "        print(f\"Tổng số cặp: {total_pairs}\")\n",
        "        print(f\"Label 0.0 (doc1 < doc2): {label_counts[0.0]} ({label_counts[0.0]/total_pairs*100:.1f}%)\")\n",
        "        print(f\"Label 0.5 (doc1 = doc2): {label_counts[0.5]} ({label_counts[0.5]/total_pairs*100:.1f}%)\")\n",
        "        print(f\"Label 1.0 (doc1 > doc2): {label_counts[1.0]} ({label_counts[1.0]/total_pairs*100:.1f}%)\")\n",
        "\n",
        "        return all_pairwise_data\n",
        "\n",
        "    def _balanced_sampling(self, pairs: List[Dict], max_pairs: int) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Lấy mẫu cân bằng theo labels\n",
        "\n",
        "        Args:\n",
        "            pairs: Danh sách tất cả các cặp\n",
        "            max_pairs: Số cặp tối đa\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: Danh sách cặp đã được sampling\n",
        "        \"\"\"\n",
        "        # Phân loại theo labels\n",
        "        label_groups = {0.0: [], 0.5: [], 1.0: []}\n",
        "        for pair in pairs:\n",
        "            label_groups[pair['label']].append(pair)\n",
        "\n",
        "        # Tính số mẫu cho mỗi label (cân bằng)\n",
        "        samples_per_label = max_pairs // 3\n",
        "        remaining = max_pairs % 3\n",
        "\n",
        "        sampled_pairs = []\n",
        "\n",
        "        # Lấy mẫu từng label\n",
        "        for i, (label, group) in enumerate(label_groups.items()):\n",
        "            n_samples = samples_per_label + (1 if i < remaining else 0)\n",
        "            n_samples = min(n_samples, len(group))  # Không vượt quá số có sẵn\n",
        "\n",
        "            # Random sampling\n",
        "            import random\n",
        "            sampled = random.sample(group, n_samples)\n",
        "            sampled_pairs.extend(sampled)\n",
        "\n",
        "        return sampled_pairs\n",
        "\n",
        "    def save_pairwise_data(self, pairwise_data: List[Dict], file_path: str,\n",
        "                          metadata: Optional[Dict] = None):\n",
        "        \"\"\"\n",
        "        Lưu dữ liệu pairwise vào file\n",
        "\n",
        "        Args:\n",
        "            pairwise_data: Dữ liệu pairwise\n",
        "            file_path: Đường dẫn file\n",
        "            metadata: Metadata bổ sung (optional)\n",
        "        \"\"\"\n",
        "        # Tạo thư mục nếu chưa có\n",
        "        os.makedirs(os.path.dirname(file_path) if os.path.dirname(file_path) else '.', exist_ok=True)\n",
        "\n",
        "        # Chuẩn bị data để lưu\n",
        "        data_to_save = {\n",
        "            \"metadata\": {\n",
        "                \"total_pairs\": len(pairwise_data),\n",
        "                \"created_by\": \"DataPreparator\",\n",
        "                \"format_version\": \"1.0\",\n",
        "                **(metadata or {})\n",
        "            },\n",
        "            \"pairwise_data\": pairwise_data\n",
        "        }\n",
        "\n",
        "        # Lưu file\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data_to_save, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"Đã lưu {len(pairwise_data)} cặp dữ liệu vào {file_path}\")\n",
        "\n",
        "    def load_pairwise_data(self, file_path: str) -> Tuple[List[Dict], Dict]:\n",
        "        \"\"\"\n",
        "        Load dữ liệu pairwise từ file\n",
        "\n",
        "        Args:\n",
        "            file_path: Đường dẫn file\n",
        "\n",
        "        Returns:\n",
        "            Tuple[List[Dict], Dict]: (pairwise_data, metadata)\n",
        "        \"\"\"\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"File không tồn tại: {file_path}\")\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        pairwise_data = data.get('pairwise_data', [])\n",
        "        metadata = data.get('metadata', {})\n",
        "\n",
        "        print(f\"Đã load {len(pairwise_data)} cặp dữ liệu từ {file_path}\")\n",
        "\n",
        "        return pairwise_data, metadata\n",
        "def prepare_training_data(documents_path: str, queries: List[str],\n",
        "                         output_file: str = \"document_pairs.json\",\n",
        "                         sentence_model_name: str = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
        "                         stopwords_path: Optional[str] = None,\n",
        "                         relevance_method: str = 'cosine_ranking',\n",
        "                         max_pairs_per_query: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Hàm wrapper để chuẩn bị dữ liệu training một cách dễ dàng\n",
        "\n",
        "    Args:\n",
        "        documents_path: Đường dẫn file documents JSON\n",
        "        queries: Danh sách queries\n",
        "        output_file: Tên file output\n",
        "        sentence_model_name: Tên sentence transformer model\n",
        "        stopwords_path: Đường dẫn stopwords file\n",
        "        relevance_method: Phương pháp tính relevance\n",
        "        max_pairs_per_query: Giới hạn cặp per query\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: Dữ liệu pairwise đã tạo\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"CHUẨN BỊ DỮ LIỆU PAIRWISE CHO RANKNET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Load documents\n",
        "    print(f\"1. Đang load documents từ {documents_path}...\")\n",
        "    with open(documents_path, 'r', encoding='utf-8') as f:\n",
        "        documents = json.load(f)\n",
        "    print(f\"   ✓ Đã load {len(documents)} documents\")\n",
        "\n",
        "    # 2. Khởi tạo sentence transformer\n",
        "    print(f\"2. Đang khởi tạo sentence transformer: {sentence_model_name}...\")\n",
        "    sentence_model = SentenceTransformer(sentence_model_name)\n",
        "    print(f\"   ✓ Model đã sẵn sàng\")\n",
        "\n",
        "    # 3. Khởi tạo DataPreparator\n",
        "    print(\"3. Đang khởi tạo DataPreparator...\")\n",
        "    preparator = DataPreparator(sentence_model, stopwords_path)\n",
        "    print(f\"   ✓ DataPreparator đã sẵn sàng\")\n",
        "\n",
        "    # 4. Tạo pairwise data\n",
        "    print(\"4. Đang tạo dữ liệu pairwise...\")\n",
        "    pairwise_data = preparator.generate_pairwise_data(\n",
        "        queries=queries,\n",
        "        documents=documents,\n",
        "        relevance_method=relevance_method,\n",
        "        max_pairs_per_query=max_pairs_per_query,\n",
        "        balance_labels=True\n",
        "    )\n",
        "    print(f\"   ✓ Đã tạo {len(pairwise_data)} cặp dữ liệu\")\n",
        "\n",
        "    # 5. Lưu file\n",
        "    print(f\"5. Đang lưu vào {output_file}...\")\n",
        "    metadata = {\n",
        "        \"documents_path\": documents_path,\n",
        "        \"num_queries\": len(queries),\n",
        "        \"queries\": queries,\n",
        "        \"relevance_method\": relevance_method,\n",
        "        \"sentence_model\": sentence_model_name,\n",
        "        \"max_pairs_per_query\": max_pairs_per_query\n",
        "    }\n",
        "\n",
        "    preparator.save_pairwise_data(pairwise_data, output_file, metadata)\n",
        "    print(f\"   ✓ Dữ liệu đã được lưu thành công\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"HOÀN THÀNH CHUẨN BỊ DỮ LIỆU!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return pairwise_data"
      ],
      "metadata": {
        "id": "8Q-8K8nHKJvX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuẩn bị dữ liệu, lấy ra so sánh\n",
        "class RankNetDataset(Dataset):\n",
        "    \"\"\"Dataset cho RankNet training\"\"\"\n",
        "    def __init__(self, pairwise_data, sentence_model):\n",
        "        self.data = pairwise_data\n",
        "        self.sentence_model = sentence_model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    #  Trả về một dictionary chứa feature1, feature2, và label\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "\n",
        "        # Encode query và documents\n",
        "        query_emb = self.sentence_model.encode([sample['query']])[0]\n",
        "        doc1_emb = self.sentence_model.encode([sample['doc1_text']])[0]\n",
        "        doc2_emb = self.sentence_model.encode([sample['doc2_text']])[0]\n",
        "\n",
        "        # Tạo features bằng cách concat query+doc\n",
        "        feature1 = np.concatenate([query_emb, doc1_emb])\n",
        "        feature2 = np.concatenate([query_emb, doc2_emb])\n",
        "\n",
        "        return {\n",
        "            'feature1': torch.tensor(feature1, dtype=torch.float32),\n",
        "            'feature2': torch.tensor(feature2, dtype=torch.float32),\n",
        "            'label': torch.tensor(sample['label'], dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "\n",
        "def evaluate_ranking(model, documents, queries, sentence_model, preparator, device, top_k=10):\n",
        "    \"\"\"\n",
        "    Đánh giá mô hình bằng cách rank lại documents cho mỗi query\n",
        "    và tính pairwise accuracy\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for query in queries:\n",
        "            # SỬA: Gọi đúng method preprocess_text\n",
        "            processed_query = preparator.preprocess_text(query)\n",
        "\n",
        "            # Encode query\n",
        "            query_emb = sentence_model.encode([processed_query])[0]\n",
        "\n",
        "            # Score tất cả documents\n",
        "            doc_scores = []\n",
        "            for doc in documents:\n",
        "                # SỬA: Gọi đúng method preprocess_text\n",
        "                processed_doc = preparator.preprocess_text(doc['value'])\n",
        "\n",
        "                doc_emb = sentence_model.encode([processed_doc])[0]\n",
        "\n",
        "                feature = torch.tensor(\n",
        "                    np.concatenate([query_emb, doc_emb]),\n",
        "                    dtype=torch.float32\n",
        "                ).unsqueeze(0).to(device)\n",
        "\n",
        "                score = model(feature).item()\n",
        "                doc_scores.append((doc['id'], score, doc))\n",
        "\n",
        "            # Sắp xếp giảm dần theo score\n",
        "            doc_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Lấy top k\n",
        "            top_docs = doc_scores[:top_k]\n",
        "\n",
        "            results[query] = {\n",
        "                'top_documents': [(doc_id, doc['value'], score) for doc_id, score, doc in top_docs],\n",
        "                'all_scores': doc_scores\n",
        "            }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QpI7PnRkybGn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hàm huấn luyện\n",
        "def train_ranknet(model, dataloader, optimizer, device, num_epochs=20,\n",
        "                          loss_type='cross_entropy', patience=5, min_delta=1e-4):\n",
        "    \"\"\"\n",
        "    Huấn luyện mô hình RankNet với các cải tiến\n",
        "\n",
        "    Args:\n",
        "        model: RankNet model\n",
        "        dataloader: DataLoader\n",
        "        optimizer: optimizer\n",
        "        device: cuda/cpu\n",
        "        num_epochs: số epochs\n",
        "        loss_type: loại loss function\n",
        "        patience: số epochs chờ để early stopping\n",
        "        min_delta: threshold nhỏ nhất để coi là improvement\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=3, verbose=True, min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            feature1 = batch['feature1'].to(device)\n",
        "            feature2 = batch['feature2'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            score1 = model(feature1).squeeze()\n",
        "            score2 = model(feature2).squeeze()\n",
        "\n",
        "            # Tính loss với hàm cải tiến\n",
        "            loss = ranknet_loss(score1, score2, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping để tránh exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'Loss': f\"{loss.item():.4f}\",\n",
        "                'LR': f\"{optimizer.param_groups[0]['lr']:.6f}\"\n",
        "            })\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        loss_history.append(avg_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_loss < best_loss - min_delta:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "            # Save best model\n",
        "            torch.save(model.state_dict(), 'best_ranknet_model.pth')\n",
        "            print(f\"New best model saved with loss: {best_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "            print(f\"Loading best model with loss: {best_loss:.4f}\")\n",
        "            model.load_state_dict(torch.load('best_ranknet_model.pth'))\n",
        "            break\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KcoSWYiDK4IR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm đánh giá kết quả\n",
        "def calculate_pairwise_accuracy(model, test_data, sentence_model, device):\n",
        "    \"\"\"Tính Pairwise Accuracy\"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sample in tqdm(test_data, desc=\"Tính Pairwise Accuracy\"):\n",
        "            # Encode features\n",
        "            query_emb = sentence_model.encode([sample['query']])[0]\n",
        "            doc1_emb = sentence_model.encode([sample['doc1_text']])[0]\n",
        "            doc2_emb = sentence_model.encode([sample['doc2_text']])[0]\n",
        "\n",
        "            feature1 = torch.tensor(np.concatenate([query_emb, doc1_emb]),\n",
        "                                  dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            feature2 = torch.tensor(np.concatenate([query_emb, doc2_emb]),\n",
        "                                  dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "            # Tính scores\n",
        "            score1 = model(feature1).item()\n",
        "            score2 = model(feature2).item()\n",
        "\n",
        "            # Dự đoán\n",
        "            if sample['label'] == 1.0:  # doc1 should be ranked higher\n",
        "                if score1 > score2:\n",
        "                    correct_predictions += 1\n",
        "            elif sample['label'] == 0.0:  # doc2 should be ranked higher\n",
        "                if score2 > score1:\n",
        "                    correct_predictions += 1\n",
        "            else:  # Equal relevance (label = 0.5)\n",
        "                # Coi như đúng nếu difference nhỏ\n",
        "                if abs(score1 - score2) < 0.1:\n",
        "                    correct_predictions += 1\n",
        "\n",
        "            total_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy\n",
        "\n",
        "  # Hàm test\n",
        "def test_specific_document_pair(model, sentence_model, preparator, documents,\n",
        "                              query, doc_id1, doc_id2, device):\n",
        "  \"\"\"\n",
        "  Test mô hình với cặp tài liệu cụ thể theo ID\n",
        "\n",
        "  Args:\n",
        "      model: RankNet model đã được huấn luyện\n",
        "      sentence_model: SentenceTransformer model\n",
        "      preparator: DataPreparator\n",
        "      documents: List tất cả documents\n",
        "      query: Query string để test\n",
        "      doc_id1, doc_id2: ID của 2 documents cần so sánh\n",
        "      device: cuda/cpu\n",
        "  \"\"\"\n",
        "  print(f\"=\"*60)\n",
        "  print(f\"TEST CẶP TÀI LIỆU CỤ THỂ\")\n",
        "  print(f\"=\"*60)\n",
        "\n",
        "  # Tìm documents theo ID\n",
        "  doc1 = None\n",
        "  doc2 = None\n",
        "\n",
        "  for doc in documents:\n",
        "      if doc['id'] == doc_id1:\n",
        "          doc1 = doc\n",
        "      elif doc['id'] == doc_id2:\n",
        "          doc2 = doc\n",
        "\n",
        "  if doc1 is None:\n",
        "      print(f\"❌ Không tìm thấy document với ID: {doc_id1}\")\n",
        "      return\n",
        "  if doc2 is None:\n",
        "      print(f\"❌ Không tìm thấy document với ID: {doc_id2}\")\n",
        "      return\n",
        "\n",
        "  print(f\"📄 Query: '{query}'\")\n",
        "  print(f\"📄 Document 1 [ID: {doc_id1}]: '{doc1['value']}'\")\n",
        "  print(f\"📄 Document 2 [ID: {doc_id2}]: '{doc2['value']}'\")\n",
        "  print()\n",
        "\n",
        "  # Preprocess và encode\n",
        "  processed_query = preparator.preprocess_text(query)\n",
        "  processed_doc1 = preparator.preprocess_text(doc1['value'])\n",
        "  processed_doc2 = preparator.preprocess_text(doc2['value'])\n",
        "\n",
        "  query_emb = sentence_model.encode([processed_query])[0]\n",
        "  doc1_emb = sentence_model.encode([processed_doc1])[0]\n",
        "  doc2_emb = sentence_model.encode([processed_doc2])[0]\n",
        "\n",
        "  # Tạo features (concatenation)\n",
        "  feature1 = np.concatenate([query_emb, doc1_emb])\n",
        "  feature2 = np.concatenate([query_emb, doc2_emb])\n",
        "\n",
        "  print(f\"🔧 Preprocessed query: '{processed_query}'\")\n",
        "  print(f\"🔧 Preprocessed doc1: '{processed_doc1}'\")\n",
        "  print(f\"🔧 Preprocessed doc2: '{processed_doc2}'\")\n",
        "  print(f\"🔧 Feature vector size: {len(feature1)}\")\n",
        "  print()\n",
        "\n",
        "  # Test với model\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      # Chuyển thành tensor\n",
        "      feature1_tensor = torch.tensor(feature1, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "      feature2_tensor = torch.tensor(feature2, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "      # Tính scores\n",
        "      score1 = model(feature1_tensor).item()\n",
        "      score2 = model(feature2_tensor).item()\n",
        "\n",
        "      # Tính xác suất\n",
        "      diff = score1 - score2\n",
        "      probability_1_better_2 = torch.sigmoid(torch.tensor(diff)).item()\n",
        "\n",
        "      print(f\"📊 KẾT QUẢ:\")\n",
        "      print(f\"   Score Document 1: {score1:.4f}\")\n",
        "      print(f\"   Score Document 2: {score2:.4f}\")\n",
        "      print(f\"   Score difference: {diff:.4f}\")\n",
        "      print(f\"   P(Doc1 > Doc2): {probability_1_better_2:.4f} ({probability_1_better_2*100:.1f}%)\")\n",
        "      print()\n",
        "\n",
        "      # Kết luận\n",
        "      if probability_1_better_2 > 0.6:\n",
        "          conclusion = f\"Document 1 (ID: {doc_id1}) có khả năng cao hơn liên quan với query\"\n",
        "      elif probability_1_better_2 < 0.4:\n",
        "          conclusion = f\"Document 2 (ID: {doc_id2}) có khả năng cao hơn liên quan với query\"\n",
        "      else:\n",
        "          conclusion = \"Hai documents có mức độ liên quan tương đương\"\n",
        "\n",
        "      print(f\"🎯 KẾT LUẬN: {conclusion}\")\n",
        "\n",
        "      # Tính cosine similarity để so sánh\n",
        "      from sklearn.metrics.pairwise import cosine_similarity\n",
        "      query_doc1_sim = cosine_similarity([query_emb], [doc1_emb])[0][0]\n",
        "      query_doc2_sim = cosine_similarity([query_emb], [doc2_emb])[0][0]\n",
        "\n",
        "      print(f\"\\n📈 SO SÁNH VỚI COSINE SIMILARITY:\")\n",
        "      print(f\"   Query vs Doc1: {query_doc1_sim:.4f}\")\n",
        "      print(f\"   Query vs Doc2: {query_doc2_sim:.4f}\")\n",
        "\n",
        "      if query_doc1_sim > query_doc2_sim:\n",
        "          cosine_conclusion = f\"Theo cosine similarity: Document 1 liên quan hơn\"\n",
        "      elif query_doc2_sim > query_doc1_sim:\n",
        "          cosine_conclusion = f\"Theo cosine similarity: Document 2 liên quan hơn\"\n",
        "      else:\n",
        "          cosine_conclusion = f\"Theo cosine similarity: Hai documents tương đương\"\n",
        "\n",
        "      print(f\"   {cosine_conclusion}\")\n",
        "\n",
        "      # So sánh kết quả\n",
        "      model_prefers_doc1 = probability_1_better_2 > 0.5\n",
        "      cosine_prefers_doc1 = query_doc1_sim > query_doc2_sim\n",
        "\n",
        "      if model_prefers_doc1 == cosine_prefers_doc1:\n",
        "          print(f\"   ✅ Model và Cosine similarity đồng ý với nhau\")\n",
        "      else:\n",
        "          print(f\"   ⚠️  Model và Cosine similarity có kết quả khác nhau\")\n",
        "\n",
        "  print(f\"=\"*60)"
      ],
      "metadata": {
        "id": "CFhp1xa9MT7Y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chạy chương trình** Tính toán chính"
      ],
      "metadata": {
        "id": "nX9zBcDTydNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Thiết lập device\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Sử dụng device: {device}\")\n",
        "\n",
        "        # Bước 1: Tải tài liệu và khởi tạo sentence-transformer\n",
        "        documents_path = \"/content/cadao_tucngu_50_1.json\"\n",
        "        pairwise_data_file = \"/content/document_pairs.json\"\n",
        "        # documents_path = \"FetchData/train/anh_em_mot_nha/data.json\"\n",
        "\n",
        "        # Chạy document để lấy đánh giá với kết quả\n",
        "        with open(documents_path, 'r', encoding='utf-8') as f:\n",
        "            documents = json.load(f)\n",
        "        stopwords_path = \"/content/vietnamese-stopwords.txt\"\n",
        "        # Tạo cặp dữ liệu huấn luyện - Cải thiện với multiple queries\n",
        "        queries = [\n",
        "            \"Anh em như thể tay chân\"\n",
        "        ]\n",
        "\n",
        "        if os.path.exists(pairwise_data_file):\n",
        "            print(f\"1. Load dữ liệu pairwise từ {pairwise_data_file}...\")\n",
        "\n",
        "            # Khởi tạo sentence model trước\n",
        "            sentence_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "            preparator = DataPreparator(sentence_model)\n",
        "\n",
        "            # Load dữ liệu\n",
        "            pairwise_data, metadata = preparator.load_pairwise_data(pairwise_data_file)\n",
        "            print(f\"   ✓ Đã load {len(pairwise_data)} cặp từ file có sẵn\")\n",
        "            print(f\"   ✓ Metadata: {metadata}\")\n",
        "\n",
        "        else:\n",
        "            print(\"1. Tạo dữ liệu pairwise mới...\")\n",
        "\n",
        "            # Tạo dữ liệu pairwise\n",
        "            pairwise_data = prepare_training_data(\n",
        "                documents_path=documents_path,\n",
        "                queries=queries,\n",
        "                output_file=pairwise_data_file,\n",
        "                stopwords_path=None,\n",
        "                relevance_method=\"cosine_ranking\",\n",
        "                max_pairs_per_query=1000\n",
        "            )\n",
        "\n",
        "            # Khởi tạo sentence model\n",
        "            sentence_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2') #384 neurons\n",
        "        # Tạo dataset và dataloader\n",
        "        print(\"Đang chuẩn bị dataset...\")\n",
        "        dataset = RankNetDataset(pairwise_data, sentence_model)\n",
        "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "\n",
        "        # Bước 2: Khởi tạo và huấn luyện mô hình RankNet\n",
        "        print(\"Đang khởi tạo mô hình RankNet...\")\n",
        "\n",
        "        # Tính kích thước input (query embedding + document embedding)\n",
        "        sample_query_emb = sentence_model.encode([\"test\"])[0]\n",
        "        input_size = len(sample_query_emb) * 2  # query + document embeddings\n",
        "        print(f\"Input size: {input_size}\")\n",
        "\n",
        "        model = RankNet(input_size=input_size, hidden_size1=128, hidden_size2=64, dropout=0.5)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "        print(\"Bắt đầu huấn luyện mô hình...\")\n",
        "        model = train_ranknet(model, dataloader, optimizer, device, num_epochs=10)\n",
        "\n",
        "        # Lưu mô hình\n",
        "        torch.save(model.state_dict(), 'ranknet_model.pth')\n",
        "        print(\"Đã lưu mô hình vào ranknet_model.pth\")\n",
        "\n",
        "                # Bước 3: Đánh giá độ chính xác của mô hình\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"ĐÁNH GIÁ MÔ HÌNH\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Test queries\n",
        "        test_queries = [\n",
        "            \"Anh em như thể tay chân\",\n",
        "        ]\n",
        "\n",
        "        print(\"Đang đánh giá ranking...\")\n",
        "        ranking_results = evaluate_ranking(model, documents, test_queries, sentence_model, preparator, device, top_k=10)\n",
        "\n",
        "\n",
        "        # Hiển thị kết quả top 10 cho mỗi query\n",
        "        for query, result in ranking_results.items():\n",
        "            print(f\"\\nQuery: '{query}'\")\n",
        "            print(\"Top 10 documents:\")\n",
        "            for i, (doc_id, doc_text, score) in enumerate(result['top_documents'], 1):\n",
        "                print(f\"{i:2d}. [ID: {doc_id}] Score: {score:.4f}\")\n",
        "                print(f\"    Text: {doc_text[:100]}...\")\n",
        "                print()\n",
        "\n",
        "        # Tính Pairwise Accuracy trên tập test\n",
        "        print(\"Đang tính Pairwise Accuracy...\")\n",
        "\n",
        "        # Tạo test data từ test queries\n",
        "        test_pairwise_data = prepare_training_data(\n",
        "                documents_path=documents_path,\n",
        "                queries=queries,\n",
        "                output_file=pairwise_data_file,\n",
        "                stopwords_path=None,\n",
        "                relevance_method=\"cosine_ranking\",\n",
        "                max_pairs_per_query=1000\n",
        "            )  # Giới hạn để tính nhanh\n",
        "        accuracy = calculate_pairwise_accuracy(model, test_pairwise_data, sentence_model, device)\n",
        "\n",
        "        print(f\"\\nPairwise Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"HOÀN THÀNH!\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n"
      ],
      "metadata": {
        "id": "LpgjMrNrMpLx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47d8ad2-f1f3-4ec8-f895-1b28e2257892"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng device: cuda\n",
            "1. Load dữ liệu pairwise từ /content/document_pairs.json...\n",
            "Đã load 1332 cặp dữ liệu từ /content/document_pairs.json\n",
            "   ✓ Đã load 1332 cặp từ file có sẵn\n",
            "   ✓ Metadata: {'total_pairs': 1332, 'created_by': 'DataPreparator', 'format_version': '1.0', 'documents_path': '/content/cadao_tucngu_50_1.json', 'num_queries': 2, 'queries': ['Anh em như thể tay chân', 'Anh em thuận hòa'], 'relevance_method': 'cosine_ranking', 'sentence_model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', 'max_pairs_per_query': 1000}\n",
            "Đang chuẩn bị dataset...\n",
            "Đang khởi tạo mô hình RankNet...\n",
            "Input size: 768\n",
            "Bắt đầu huấn luyện mô hình...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 42/42 [00:41<00:00,  1.01it/s, Loss=0.6480, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Loss: 0.6386\n",
            "New best model saved with loss: 0.6386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 42/42 [00:40<00:00,  1.04it/s, Loss=0.5373, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Average Loss: 0.5524\n",
            "New best model saved with loss: 0.5524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 42/42 [00:40<00:00,  1.04it/s, Loss=0.4719, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Average Loss: 0.4960\n",
            "New best model saved with loss: 0.4960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 42/42 [00:41<00:00,  1.01it/s, Loss=0.4602, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Average Loss: 0.4671\n",
            "New best model saved with loss: 0.4671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 42/42 [00:40<00:00,  1.05it/s, Loss=0.5605, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average Loss: 0.4508\n",
            "New best model saved with loss: 0.4508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 42/42 [00:40<00:00,  1.03it/s, Loss=0.4524, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Average Loss: 0.4304\n",
            "New best model saved with loss: 0.4304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 42/42 [00:40<00:00,  1.03it/s, Loss=0.5322, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Average Loss: 0.4276\n",
            "New best model saved with loss: 0.4276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 42/42 [00:41<00:00,  1.02it/s, Loss=0.5125, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Average Loss: 0.4181\n",
            "New best model saved with loss: 0.4181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 42/42 [00:40<00:00,  1.03it/s, Loss=0.4021, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Average Loss: 0.4154\n",
            "New best model saved with loss: 0.4154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 42/42 [00:40<00:00,  1.05it/s, Loss=0.3956, LR=0.001000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Average Loss: 0.4068\n",
            "New best model saved with loss: 0.4068\n",
            "Đã lưu mô hình vào ranknet_model.pth\n",
            "\n",
            "==================================================\n",
            "ĐÁNH GIÁ MÔ HÌNH\n",
            "==================================================\n",
            "Đang đánh giá ranking...\n",
            "\n",
            "Query: 'Anh em như thể tay chân'\n",
            "Top 10 documents:\n",
            " 1. [ID: 33] Score: 4.3795\n",
            "    Text: Anh em như thể tay chân....\n",
            "\n",
            " 2. [ID: 256] Score: 4.2375\n",
            "    Text: Chị em dâu như bầu nước lã...\n",
            "\n",
            " 3. [ID: 6] Score: 4.1990\n",
            "    Text: Anh em như thể chân tay Rách lành đùm bọc, dở hay đỡ đần...\n",
            "\n",
            " 4. [ID: 60] Score: 4.1346\n",
            "    Text: Anh em như chân với tay Rách lành đùm bọc, dở hay đỡ đần....\n",
            "\n",
            " 5. [ID: 683] Score: 4.0680\n",
            "    Text: Nhiễu điều phủ lấy giá gương Chạy xe nhường nhịn, là thương chính mình...\n",
            "\n",
            " 6. [ID: 768] Score: 3.6605\n",
            "    Text: Thương người như thể thương thân....\n",
            "\n",
            " 7. [ID: 83] Score: 3.4763\n",
            "    Text: Anh em ăn ở thuận hoà Chớ điều chếch lệch người ta chê cười...\n",
            "\n",
            " 8. [ID: 697] Score: 2.9633\n",
            "    Text: Nhường nhau không phải là hèn Nhường nhau để khỏi lách, lèn, kẹt xe...\n",
            "\n",
            " 9. [ID: 75] Score: 2.8733\n",
            "    Text: Anh em như thể chân tay Cùng cha cùng mẹ việc nhà hăng say...\n",
            "\n",
            "10. [ID: 647] Score: 1.9389\n",
            "    Text: Nhất cận thị, nhì cận lân...\n",
            "\n",
            "Đang tính Pairwise Accuracy...\n",
            "============================================================\n",
            "CHUẨN BỊ DỮ LIỆU PAIRWISE CHO RANKNET\n",
            "============================================================\n",
            "1. Đang load documents từ /content/cadao_tucngu_50_1.json...\n",
            "   ✓ Đã load 49 documents\n",
            "2. Đang khởi tạo sentence transformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2...\n",
            "   ✓ Model đã sẵn sàng\n",
            "3. Đang khởi tạo DataPreparator...\n",
            "   ✓ DataPreparator đã sẵn sàng\n",
            "4. Đang tạo dữ liệu pairwise...\n",
            "Bắt đầu tạo dữ liệu pairwise với 1 queries và 49 documents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tạo dữ liệu pairwise: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Thống kê dữ liệu pairwise:\n",
            "Tổng số cặp: 666\n",
            "Label 0.0 (doc1 < doc2): 0 (0.0%)\n",
            "Label 0.5 (doc1 = doc2): 565 (84.8%)\n",
            "Label 1.0 (doc1 > doc2): 611 (91.7%)\n",
            "   ✓ Đã tạo 666 cặp dữ liệu\n",
            "5. Đang lưu vào /content/document_pairs.json...\n",
            "Đã lưu 666 cặp dữ liệu vào /content/document_pairs.json\n",
            "   ✓ Dữ liệu đã được lưu thành công\n",
            "============================================================\n",
            "HOÀN THÀNH CHUẨN BỊ DỮ LIỆU!\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tính Pairwise Accuracy: 100%|██████████| 666/666 [00:21<00:00, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pairwise Accuracy: 0.9790 (97.90%)\n",
            "\n",
            "==================================================\n",
            "HOÀN THÀNH!\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiến hành kiểm thử mô hình [RankNet] đã được huấn luyện, chúng ta sẽ kiểm tra đơn giản bằng cách - đầu vào chúng ta sẽ cho 2 tài liệu ( di ) và ( dj ) (ở dạng 2 vectors)\n",
        "\n",
        "Sau đó chúng ta sẽ dùng mô hình [RankNet] để dự đoán thử xác suất tài liệu ( di ) liên quan với truy vấn ( q ) nhiều hơn ( dj )"
      ],
      "metadata": {
        "id": "dhEk7slbCqBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Sử dụng device: {device}\")\n",
        "\n",
        "        # Load documents\n",
        "        documents_path = \"/content/cadao_tucngu_50_1.json\"\n",
        "        model_path = \"/content/ranknet_model.pth\"\n",
        "\n",
        "        with open(documents_path, 'r', encoding='utf-8') as f:\n",
        "            documents = json.load(f)\n",
        "\n",
        "        # Khởi tạo models\n",
        "        sentence_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "        preparator = DataPreparator(sentence_model)\n",
        "\n",
        "        # Load RankNet model\n",
        "        sample_query_emb = sentence_model.encode([\"test\"])[0]\n",
        "        input_size = len(sample_query_emb) * 2\n",
        "\n",
        "        if os.path.exists(model_path):\n",
        "            checkpoint = torch.load(model_path, map_location=device)\n",
        "            fc1_weight_shape = checkpoint['fc1.weight'].shape\n",
        "            fc2_weight_shape = checkpoint['fc2.weight'].shape\n",
        "            hidden_size1 = fc1_weight_shape[0]\n",
        "            hidden_size2 = fc2_weight_shape[0]\n",
        "\n",
        "            model = RankNet(input_size=input_size, hidden_size1=hidden_size1,\n",
        "                          hidden_size2=hidden_size2, dropout=0.5)\n",
        "            model.load_state_dict(checkpoint)\n",
        "            model.to(device)\n",
        "            print(f\"✅ Đã load model từ {model_path}\")\n",
        "        else:\n",
        "            print(f\"❌ Không tìm thấy model file: {model_path}\")\n",
        "            exit()\n",
        "\n",
        "        # TEST CỤ THỂ\n",
        "        query = \"Bán anh em xa\"\n",
        "        doc_id1 = 75\n",
        "        doc_id2 = 107\n",
        "\n",
        "        test_specific_document_pair(\n",
        "            model=model,\n",
        "            sentence_model=sentence_model,\n",
        "            preparator=preparator,\n",
        "            documents=documents,\n",
        "            query=query,\n",
        "            doc_id1=doc_id1,\n",
        "            doc_id2=doc_id2,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WlKuK5xCuSu",
        "outputId": "3391fd61-be40-4c2a-914d-cc5217274691"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng device: cuda\n",
            "✅ Đã load model từ /content/ranknet_model.pth\n",
            "============================================================\n",
            "TEST CẶP TÀI LIỆU CỤ THỂ\n",
            "============================================================\n",
            "📄 Query: 'Bán anh em xa'\n",
            "📄 Document 1 [ID: 75]: 'Anh em như thể chân tay Cùng cha cùng mẹ việc nhà hăng say'\n",
            "📄 Document 2 [ID: 107]: 'Bán anh em xa, mua láng giềng gần'\n",
            "\n",
            "🔧 Preprocessed query: 'bán anh_em xa'\n",
            "🔧 Preprocessed doc1: 'anh_em như thê chân tay cu ng cha cu ng me việc nhà hăng_say'\n",
            "🔧 Preprocessed doc2: 'bán anh_em xa mua láng_giềng gần'\n",
            "🔧 Feature vector size: 768\n",
            "\n",
            "📊 KẾT QUẢ:\n",
            "   Score Document 1: 4.1221\n",
            "   Score Document 2: -0.8170\n",
            "   Score difference: 4.9391\n",
            "   P(Doc1 > Doc2): 0.9929 (99.3%)\n",
            "\n",
            "🎯 KẾT LUẬN: Document 1 (ID: 75) có khả năng cao hơn liên quan với query\n",
            "\n",
            "📈 SO SÁNH VỚI COSINE SIMILARITY:\n",
            "   Query vs Doc1: 0.6656\n",
            "   Query vs Doc2: 0.8163\n",
            "   Theo cosine similarity: Document 2 liên quan hơn\n",
            "   ⚠️  Model và Cosine similarity có kết quả khác nhau\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}