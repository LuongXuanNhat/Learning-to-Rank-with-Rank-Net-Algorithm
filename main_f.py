import json
import math
import re
from collections import Counter, defaultdict
import os
import numpy as np
from itertools import combinations
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from pyvi import ViTokenizer

class TFIDF:
    def __init__(self, documents, stopword_path=None):
        """
        Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng TFIDF v·ªõi t·∫≠p vƒÉn b·∫£n d·∫°ng chu·ªói, t·ª± ƒë·ªông l·ªçc stopword v√† t√°ch t·ª´.
        Args:
            documents (List[str]): Danh s√°ch c√°c c√¢u (chu·ªói).
            stopword_path (str): ƒê∆∞·ªùng d·∫´n file stopword (m·ªói d√≤ng 1 t·ª´/c·ª•m t·ª´).
        """
        self.stopwords = set()
        if stopword_path and os.path.exists(stopword_path):
            try:
                with open(stopword_path, encoding="utf-8") as f:
                    self.stopwords = set(line.strip() for line in f if line.strip())
            except Exception as e:
                print(f"Warning: Could not load stopwords from {stopword_path}: {e}")
        
        # Ti·ªÅn x·ª≠ l√Ω: t√°ch t·ª´ v√† l·ªçc stopword
        self.documents = [self._preprocess(doc) for doc in documents if doc.strip()]
        self.N = len(self.documents)
        if self.N == 0:
            raise ValueError("No valid documents found after preprocessing")
        self.idf = self._compute_idf()

    def _preprocess(self, text):
        """
        [ƒê√£ n√¢ng c·∫•p] S·ª≠ d·ª•ng PyVi
        T√°ch t·ª´ ƒë∆°n gi·∫£n (theo kho·∫£ng tr·∫Øng) v√† lo·∫°i b·ªè stopword.
        Args:
            text (str): C√¢u ƒë·∫ßu v√†o.
        Returns:
            List[str]: Danh s√°ch t·ª´ ƒë√£ l·ªçc stopword.
        """
        # 1. Chu·∫©n h√≥a: b·ªè d·∫•u c√¢u, k√Ω t·ª± ƒë·∫∑c bi·ªát, s·ªë (n·∫øu c·∫ßn)
        text = text.lower()
        text = re.sub(r'[^\w\s]', ' ', text)  # lo·∫°i b·ªè d·∫•u c√¢u
        text = re.sub(r'\d+', ' ', text)      # lo·∫°i b·ªè s·ªë
        text = re.sub(r'\s+', ' ', text).strip()  # b·ªè kho·∫£ng tr·∫Øng th·ª´a

        # 2. Tokenize v·ªõi PyVi
        tokenized = ViTokenizer.tokenize(text) # t·ª´ ƒë∆°n, t·ª´ gh√©p, c·ª•m t·ª´ c·ªë ƒë·ªãnh | √îng Nguy·ªÖn_T·∫•n_D≈©ng l√† c·ª±u_th·ªß_t∆∞·ªõng Vi·ªát_Nam .

        # 3. T√°ch th√†nh danh s√°ch t·ª´
        tokens = tokenized.split()

        # 4. Lo·∫°i b·ªè stopwords n·∫øu c√≥
        if self.stopwords:
            tokens = [w for w in tokens if w not in self.stopwords]

        return tokens

    def _compute_idf(self):
        """
        T√≠nh to√°n gi√° tr·ªã IDF (Inverse Document Frequency) cho t·ª´ng t·ª´ trong t·∫≠p vƒÉn b·∫£n.
        Returns:
            dict: T·ª´ ƒëi·ªÉn ch·ª©a idf c·ªßa t·ª´ng t·ª´.
        """
        idf = defaultdict(lambda: 0)
        for doc in self.documents:
            unique_terms = set(doc)
            for term in unique_terms:
                idf[term] += 1
        for term in idf:
            idf[term] = math.log((self.N + 1) / (idf[term] + 1)) + 1
        return dict(idf)

    def compute_tf(self, doc):
        """
        T√≠nh to√°n gi√° tr·ªã TF (Term Frequency) cho m·ªôt vƒÉn b·∫£n.
        Args:
            doc (List[str]): VƒÉn b·∫£n c·∫ßn t√≠nh TF, l√† list c√°c t·ª´ ƒë√£ t√°ch.
        Returns:
            dict: T·ª´ ƒëi·ªÉn ch·ª©a tf c·ªßa t·ª´ng t·ª´ trong vƒÉn b·∫£n.
        """
        if not doc:
            return {}
        tf = Counter(doc)
        total_terms = len(doc)
        return {term: count / total_terms for term, count in tf.items()}

    def compute_tfidf(self, doc):
        """
        T√≠nh to√°n gi√° tr·ªã TF-IDF cho m·ªôt vƒÉn b·∫£n.
        Args:
            doc (List[str]): VƒÉn b·∫£n c·∫ßn t√≠nh TF-IDF, l√† list c√°c t·ª´ ƒë√£ t√°ch.
        Returns:
            dict: T·ª´ ƒëi·ªÉn ch·ª©a tf-idf c·ªßa t·ª´ng t·ª´ trong vƒÉn b·∫£n.
        """
        tf = self.compute_tf(doc)
        tfidf = {}
        for term, tf_val in tf.items():
            idf_val = self.idf.get(term, math.log((self.N + 1) / 1) + 1)
            tfidf[term] = tf_val * idf_val
        return tfidf

    def get_feature_names(self):
        """
        L·∫•y danh s√°ch c√°c t·ª´ (feature) ƒë√£ xu·∫•t hi·ªán trong t·∫≠p vƒÉn b·∫£n hu·∫•n luy·ªán.
        Returns:
            List[str]: Danh s√°ch c√°c t·ª´ (feature names).
        """
        return list(self.idf.keys())

    def transform(self, doc):
        """
        Chuy·ªÉn m·ªôt vƒÉn b·∫£n th√†nh vector TF-IDF theo th·ª© t·ª± c√°c t·ª´ trong get_feature_names().
        Args:
            doc (str): VƒÉn b·∫£n c·∫ßn chuy·ªÉn ƒë·ªïi, l√† chu·ªói.
        Returns:
            List[float]: Vector TF-IDF t∆∞∆°ng ·ª©ng v·ªõi vƒÉn b·∫£n.
        """
        tokens = self._preprocess(doc)
        tfidf = self.compute_tfidf(tokens)
        features = self.get_feature_names()
        return [tfidf.get(term, 0.0) for term in features]

    def fit_transform(self):
        """
        Tr·∫£ v·ªÅ ma tr·∫≠n TF-IDF cho to√†n b·ªô t·∫≠p vƒÉn b·∫£n ban ƒë·∫ßu (m·ªói d√≤ng l√† vector c·ªßa 1 vƒÉn b·∫£n).
        Returns:
            List[List[float]]: Ma tr·∫≠n TF-IDF (s·ªë vƒÉn b·∫£n x s·ªë feature).
        """
        features = self.get_feature_names()
        matrix = []
        for doc in self.documents:
            tfidf = self.compute_tfidf(doc)
            row = [tfidf.get(term, 0.0) for term in features]
            matrix.append(row)
        return matrix
    
class RankNet(nn.Module):
    def __init__(self, input_size, hidden_size1=256, hidden_size2=128, dropout=0.2):
        """
        RankNet v·ªõi 2 t·∫ßng ·∫©n
        
        Args:
            input_size (int): S·ªë features ƒë·∫ßu v√†o
            hidden_size1 (int): S·ªë neurons t·∫ßng ·∫©n th·ª© nh·∫•t
            hidden_size2 (int): S·ªë neurons t·∫ßng ·∫©n th·ª© hai  
            dropout (float): T·ª∑ l·ªá dropout ƒë·ªÉ tr√°nh overfitting
        """
        super(RankNet, self).__init__()
        
        # ƒê·ªãnh nghƒ©a c√°c t·∫ßng
        self.fc1 = nn.Linear(input_size, hidden_size1)
        self.fc2 = nn.Linear(hidden_size1, hidden_size2)
        self.fc3 = nn.Linear(hidden_size2, 1)  # Output layer cho score
        
        # Dropout layers
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        
        # Layer normalization thay v√¨ batch normalization ƒë·ªÉ tr√°nh l·ªói khi batch_size=1
        self.ln1 = nn.LayerNorm(hidden_size1)
        self.ln2 = nn.LayerNorm(hidden_size2)
        
    def forward(self, x):
        """
        Forward pass
        
        Args:
            x (torch.Tensor): Input tensor c√≥ shape (batch_size, input_size)
            
        Returns:
            torch.Tensor: Output scores c√≥ shape (batch_size, 1)
        """
        # ƒê·∫£m b·∫£o input l√† tensor v√† c√≥ ƒë√∫ng ki·ªÉu d·ªØ li·ªáu
        if not isinstance(x, torch.Tensor):
            x = torch.tensor(x, dtype=torch.float32)
        
        # T·∫ßng ·∫©n th·ª© nh·∫•t
        x = self.fc1(x)
        x = self.ln1(x)
        x = F.relu(x)
        x = self.dropout1(x)
        
        # T·∫ßng ·∫©n th·ª© hai
        x = self.fc2(x)
        x = self.ln2(x)
        x = F.relu(x)
        x = self.dropout2(x)
        
        # Output layer
        x = self.fc3(x)
        
        return x
    
    def predict_rank(self, x1, x2):
        """
        So s√°nh ranking gi·ªØa hai samples
        
        Args:
            x1, x2 (torch.Tensor): Hai samples c·∫ßn so s√°nh
            
        Returns:
            torch.Tensor: X√°c su·∫•t x1 ƒë∆∞·ª£c rank cao h∆°n x2
        """
        score1 = self.forward(x1)
        score2 = self.forward(x2)
        
        # S·ª≠ d·ª•ng sigmoid ƒë·ªÉ chuy·ªÉn v·ªÅ x√°c su·∫•t
        prob = torch.sigmoid(score1 - score2)
        return prob

def ranknet_loss(s_i, s_j, P_ij):
    diff = s_i - s_j
    P_hat = torch.sigmoid(diff)  # X√°c su·∫•t d·ª± ƒëo√°n PÃÇ·µ¢‚±º
    # Th√™m epsilon ƒë·ªÉ tr√°nh log(0)
    epsilon = 1e-10
    loss = -P_ij * torch.log(P_hat + epsilon) - (1 - P_ij) * torch.log(1 - P_hat + epsilon)
    return loss.mean()

class RankNetDataset(Dataset):
    def __init__(self, pairs, tfidf_matrix):
        self.pairs = pairs
        self.tfidf_matrix = tfidf_matrix

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        (di_vec, dj_vec), pij = self.pairs[idx]
        return (torch.tensor(di_vec, dtype=torch.float32),
                torch.tensor(dj_vec, dtype=torch.float32),
                torch.tensor(pij, dtype=torch.float32))

def load_documents_from_json(documents_path):
    try:
        with open(documents_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        documents = [item['value'] for item in data if 'value' in item and item['value'].strip()]
        if not documents:
            raise ValueError("No valid documents found in JSON file")
        return documents
    except Exception as e:
        print(f"Error loading documents from {documents_path}: {e}")
        raise

def relevance_score_tfidf(tfidf_matrix, vocab, query, doc_idx, tfidf_model=None):
    """
    T√≠nh ƒëi·ªÉm li√™n quan c·ªßa t√†i li·ªáu d·ª±a tr√™n query.
    C·∫£i thi·ªán: s·ª≠ d·ª•ng cosine similarity gi·ªØa query vector v√† document vector.
    
    Args:
        tfidf_matrix: Ma tr·∫≠n TF-IDF
        vocab: T·ª´ ƒëi·ªÉn c√°c t·ª´
        query: Chu·ªói truy v·∫•n (c√≥ th·ªÉ c√≥ nhi·ªÅu t·ª´)
        doc_idx: Index c·ªßa t√†i li·ªáu
        tfidf_model: ƒê·ªëi t∆∞·ª£ng TFIDF ƒë·ªÉ transform query
    
    Returns:
        float: ƒêi·ªÉm cosine similarity gi·ªØa query v√† document
    """
    if tfidf_model:
        # S·ª≠ d·ª•ng TF-IDF model ƒë·ªÉ transform query
        query_vector = tfidf_model.transform(query)
    else:
        # Fallback v·ªÅ ph∆∞∆°ng ph√°p c≈©
        query = query.lower().strip()
        query_words = query.split()
        
        # T·∫°o query vector
        query_vector = [0.0] * len(vocab)
        for word in query_words:
            word = word.strip()
            if word and word in vocab:
                word_idx = vocab.index(word)
                query_vector[word_idx] = 1.0  # Binary weight
    
    # L·∫•y document vector
    doc_vector = tfidf_matrix[doc_idx]
    
    # T√≠nh cosine similarity
    query_norm = np.linalg.norm(query_vector)
    doc_norm = np.linalg.norm(doc_vector)
    
    if query_norm == 0 or doc_norm == 0:
        return 0.0
    
    cosine_sim = np.dot(query_vector, doc_vector) / (query_norm * doc_norm)
    return cosine_sim

def calculate_precision_at_k(true_relevance_scores, predicted_ranking, k=10, threshold=0.1):
    """
    T√≠nh Precision@K cho k·∫øt qu·∫£ ranking.
    
    Args:
        true_relevance_scores (list): ƒêi·ªÉm li√™n quan th·ª±c t·∫ø c·ªßa c√°c documents (theo th·ª© t·ª± g·ªëc)
        predicted_ranking (list): Danh s√°ch (score, doc_index) ƒë∆∞·ª£c s·∫Øp x·∫øp theo score gi·∫£m d·∫ßn
        k (int): S·ªë l∆∞·ª£ng documents top-k c·∫ßn ƒë√°nh gi√°
        threshold (float): Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh document c√≥ relevant hay kh√¥ng
    
    Returns:
        float: Precision@K (t·ª´ 0 ƒë·∫øn 1)
    """
    if k <= 0 or len(predicted_ranking) == 0:
        return 0.0
    
    # L·∫•y top-k documents t·ª´ k·∫øt qu·∫£ ranking
    top_k_docs = predicted_ranking[:k]
    
    # ƒê·∫øm s·ªë documents relevant trong top-k
    relevant_in_topk = 0
    for score, doc_idx in top_k_docs:
        if doc_idx < len(true_relevance_scores):
            if true_relevance_scores[doc_idx] >= threshold:
                relevant_in_topk += 1
    
    precision_at_k = relevant_in_topk / k
    return precision_at_k

def calculate_recall_at_k(true_relevance_scores, predicted_ranking, k=10, threshold=0.1):
    """
    T√≠nh Recall@K cho k·∫øt qu·∫£ ranking.
    
    Args:
        true_relevance_scores (list): ƒêi·ªÉm li√™n quan th·ª±c t·∫ø c·ªßa c√°c documents (theo th·ª© t·ª± g·ªëc)
        predicted_ranking (list): Danh s√°ch (score, doc_index) ƒë∆∞·ª£c s·∫Øp x·∫øp theo score gi·∫£m d·∫ßn
        k (int): S·ªë l∆∞·ª£ng documents top-k c·∫ßn ƒë√°nh gi√°
        threshold (float): Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh document c√≥ relevant hay kh√¥ng
    
    Returns:
        float: Recall@K (t·ª´ 0 ƒë·∫øn 1)
    """
    if k <= 0 or len(predicted_ranking) == 0:
        return 0.0
    
    # ƒê·∫øm t·ªïng s·ªë documents relevant trong to√†n b·ªô t·∫≠p d·ªØ li·ªáu
    total_relevant = sum(1 for score in true_relevance_scores if score >= threshold)
    
    if total_relevant == 0:
        return 0.0  # Kh√¥ng c√≥ document n√†o relevant
    
    # L·∫•y top-k documents t·ª´ k·∫øt qu·∫£ ranking
    top_k_docs = predicted_ranking[:k]
    
    # ƒê·∫øm s·ªë documents relevant trong top-k
    relevant_in_topk = 0
    for score, doc_idx in top_k_docs:
        if doc_idx < len(true_relevance_scores):
            if true_relevance_scores[doc_idx] >= threshold:
                relevant_in_topk += 1
    
    recall_at_k = relevant_in_topk / total_relevant
    return recall_at_k

def calculate_f1_score_at_k(true_relevance_scores, predicted_ranking, k=10, threshold=0.1):
    """
    T√≠nh F1-Score@K cho k·∫øt qu·∫£ ranking.
    F1-Score l√† trung b√¨nh ƒëi·ªÅu h√≤a c·ªßa Precision v√† Recall.
    
    Args:
        true_relevance_scores (list): ƒêi·ªÉm li√™n quan th·ª±c t·∫ø c·ªßa c√°c documents (theo th·ª© t·ª± g·ªëc)
        predicted_ranking (list): Danh s√°ch (score, doc_index) ƒë∆∞·ª£c s·∫Øp x·∫øp theo score gi·∫£m d·∫ßn
        k (int): S·ªë l∆∞·ª£ng documents top-k c·∫ßn ƒë√°nh gi√°
        threshold (float): Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh document c√≥ relevant hay kh√¥ng
    
    Returns:
        float: F1-Score@K (t·ª´ 0 ƒë·∫øn 1)
    """
    precision_k = calculate_precision_at_k(true_relevance_scores, predicted_ranking, k, threshold)
    recall_k = calculate_recall_at_k(true_relevance_scores, predicted_ranking, k, threshold)
    
    # T√≠nh F1-Score = 2 * (precision * recall) / (precision + recall)
    if (precision_k + recall_k) == 0:
        return 0.0
    
    f1_score = 2 * (precision_k * recall_k) / (precision_k + recall_k)
    return f1_score

def calculate_average_precision(true_relevance_scores, predicted_ranking, threshold=0.1):
    """
    T√≠nh Average Precision (AP) cho k·∫øt qu·∫£ ranking.
    AP t√≠nh trung b√¨nh c·ªßa Precision@k cho t·∫•t c·∫£ c√°c v·ªã tr√≠ k m√† c√≥ document relevant.
    
    Args:
        true_relevance_scores (list): ƒêi·ªÉm li√™n quan th·ª±c t·∫ø c·ªßa c√°c documents (theo th·ª© t·ª± g·ªëc)
        predicted_ranking (list): Danh s√°ch (score, doc_index) ƒë∆∞·ª£c s·∫Øp x·∫øp theo score gi·∫£m d·∫ßn
        threshold (float): Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh document c√≥ relevant hay kh√¥ng
    
    Returns:
        float: Average Precision (t·ª´ 0 ƒë·∫øn 1)
    """
    if len(predicted_ranking) == 0:
        return 0.0
    
    # ƒê·∫øm t·ªïng s·ªë documents relevant
    total_relevant = sum(1 for score in true_relevance_scores if score >= threshold)
    if total_relevant == 0:
        return 0.0
    
    precision_sum = 0.0
    relevant_found = 0
    
    for i, (score, doc_idx) in enumerate(predicted_ranking):
        if doc_idx < len(true_relevance_scores):
            if true_relevance_scores[doc_idx] >= threshold:
                relevant_found += 1
                precision_at_i = relevant_found / (i + 1)
                precision_sum += precision_at_i
    
    average_precision = precision_sum / total_relevant if total_relevant > 0 else 0.0
    return average_precision

if __name__ == "__main__":
    try:
        # B∆∞·ªõc 1: T·∫£i t√†i li·ªáu v√† bi·ªÉu di·ªÖn TF-IDF
        documents_path = "FetchData/output/cadao_tucngu_medium.json"
        # documents_path = "FetchData/train/anh_em_mot_nha/data.json"
        documents = load_documents_from_json(documents_path)
        print("S·ªë t√†i li·ªáu:", len(documents))

        stopword_path = "../../vietnamese-stopwords.txt"
        tfidf_model = TFIDF(documents, stopword_path=stopword_path)
        matrix = tfidf_model.fit_transform()
        vocab = tfidf_model.get_feature_names()
        print("S·ªë t·ª´ trong t·ª´ ƒëi·ªÉn:", len(vocab))
        print("K√≠ch th∆∞·ªõc ma tr·∫≠n TF-IDF:", len(matrix))

        # B∆∞·ªõc 2: T·∫°o c·∫∑p d·ªØ li·ªáu hu·∫•n luy·ªán - C·∫£i thi·ªán v·ªõi multiple queries
        queries = ["nh·ªõ v·ªÅ qu√™", "qu√™ h∆∞∆°ng", "v·ªÅ qu√™", "nh·ªõ nh√†", "qu√™ ngo·∫°i", "qu√™ n·ªôi"]
        
        # T√≠nh ƒëi·ªÉm li√™n quan t·ªïng h·ª£p t·ª´ nhi·ªÅu query
        all_scores = []
        for query in queries:
            query_scores = [relevance_score_tfidf(matrix, vocab, query, i, tfidf_model) for i in range(len(documents))]
            all_scores.append(query_scores)
            print(f"ƒêi·ªÉm li√™n quan c·ªßa t·ª´ '{query}': min={min(query_scores):.4f}, max={max(query_scores):.4f}")
        
        # T√≠nh ƒëi·ªÉm trung b√¨nh t·ª´ c√°c query
        scores = [sum(score_list[i] for score_list in all_scores) / len(queries) 
                 for i in range(len(documents))]
        print(f"ƒêi·ªÉm li√™n quan t·ªïng h·ª£p: min={min(scores):.4f}, max={max(scores):.4f}")

        pairs = []
        # TƒÉng threshold ƒë·ªÉ t·∫°o ra c√°c c·∫∑p c√≥ s·ª± kh√°c bi·ªát r√µ r√†ng h∆°n
        threshold = 0.001
        for i, j in combinations(range(len(documents)), 2):
            if abs(scores[i] - scores[j]) < threshold:  # Ch·ªâ l·∫•y c·∫∑p c√≥ s·ª± kh√°c bi·ªát r√µ r√†ng
                continue
            dij = (matrix[i], matrix[j])  # C·∫∑p vector TF-IDF
            pij = 1.0 if scores[i] > scores[j] else 0.0
            pairs.append((dij, pij))
        print(f"S·ªë c·∫∑p t√†i li·ªáu: {len(pairs)}")

        if len(pairs) == 0:
            print("Warning: No training pairs generated. Check your data and query.")
            exit(1)

        # Split training/validation
        split_idx = int(0.8 * len(pairs))
        train_pairs = pairs[:split_idx]
        val_pairs = pairs[split_idx:]
        
        print(f"Training pairs: {len(train_pairs)}, Validation pairs: {len(val_pairs)}")

        # B∆∞·ªõc 3: Hu·∫•n luy·ªán RankNet - C·∫£i thi·ªán hyperparameters
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {device}")
        
        # C·∫£i thi·ªán model architecture
        model = RankNet(input_size=len(vocab), hidden_size1=256, hidden_size2=128, dropout=0.3).to(device)
        
        # S·ª≠ d·ª•ng learning rate scheduling
        optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, threshold=0.001)
        
        train_dataset = RankNetDataset(train_pairs, matrix)
        val_dataset = RankNetDataset(val_pairs, matrix)
        train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)

        epochs = 500  # TƒÉng s·ªë epoch
        best_val_loss = float('inf')
        patience = 50  # TƒÉng patience
        patience_counter = 0
        
        for epoch in range(epochs):
            # Training
            model.train()
            total_loss = 0
            for di_vec, dj_vec, pij in train_dataloader:
                di_vec, dj_vec, pij = di_vec.to(device), dj_vec.to(device), pij.to(device)
                
                optimizer.zero_grad()
                si = model(di_vec)  # ƒêi·ªÉm s·ªë cho d·µ¢
                sj = model(dj_vec)  # ƒêi·ªÉm s·ªë cho d‚±º
                loss = ranknet_loss(si, sj, pij)
                loss.backward()
                
                # Gradient clipping ƒë·ªÉ tr√°nh exploding gradients
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                total_loss += loss.item()
            
            avg_train_loss = total_loss / len(train_dataloader)
            
            # Validation
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for di_vec, dj_vec, pij in val_dataloader:
                    di_vec, dj_vec, pij = di_vec.to(device), dj_vec.to(device), pij.to(device)
                    si = model(di_vec)
                    sj = model(dj_vec)
                    loss = ranknet_loss(si, sj, pij)
                    val_loss += loss.item()
            
            avg_val_loss = val_loss / len(val_dataloader) if len(val_dataloader) > 0 else float('inf')
            
            # Update learning rate scheduler
            scheduler.step(avg_val_loss)
            
            # Early stopping
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                # Save best model
                torch.save(model.state_dict(), 'best_model.pth')
            else:
                patience_counter += 1
            
            if epoch % 20 == 0:  # In th√¥ng tin m·ªói 20 epoch
                current_lr = optimizer.param_groups[0]['lr']
                print(f"Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {current_lr:.6f}")
            
            if patience_counter >= patience:
                print(f"Early stopping at epoch {epoch}")
                break

        # Load best model
        model.load_state_dict(torch.load('best_model.pth'))

        # B∆∞·ªõc 4: D·ª± ƒëo√°n v√† x·∫øp h·∫°ng
        model.eval()
        scores_rank = []
        with torch.no_grad():
            for i in range(len(documents)):
                input_tensor = torch.tensor(matrix[i], dtype=torch.float32).to(device)
                score = model(input_tensor.unsqueeze(0)).item()  # Th√™m batch dimension
                scores_rank.append((score, i))  # L∆∞u index ƒë·ªÉ t√≠nh evaluation metrics

        ranked = sorted(scores_rank, key=lambda x: x[0], reverse=True)
        
        # T√≠nh to√°n evaluation metrics
        print(f"\nüìä ƒê√ÅNH GI√Å HI·ªÜU SU·∫§T RANKING:")
        print("=" * 80)
        
        # T√≠nh Precision@K v√† Recall@K cho c√°c gi√° tr·ªã K kh√°c nhau
        k_values = [5, 10, 15, 20]
        threshold = 0.05  # Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh document relevant
        
        print(f"Threshold ƒë·ªÉ x√°c ƒë·ªãnh relevant document: {threshold}")
        print(f"S·ªë documents c√≥ ƒëi·ªÉm ‚â• {threshold}: {sum(1 for s in scores if s >= threshold)}")
        print()
        
        for k in k_values:
            precision_k = calculate_precision_at_k(scores, ranked, k, threshold)
            recall_k = calculate_recall_at_k(scores, ranked, k, threshold)
            f1_k = calculate_f1_score_at_k(scores, ranked, k, threshold)
            
            print(f"üìà Top-{k:2d} Results:")
            print(f"   Precision@{k}: {precision_k:.4f}")
            print(f"   Recall@{k}:    {recall_k:.4f}")
            print(f"   F1-Score@{k}:  {f1_k:.4f}")
            print()
        
        # T√≠nh Average Precision (AP) - m·ªôt metric quan tr·ªçng kh√°c
        avg_precision = calculate_average_precision(scores, ranked, threshold)
        print(f"üìä ADDITIONAL METRICS:")
        print(f"   Average Precision (AP): {avg_precision:.4f}")
        print()
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ranking
        print(f"üèÜ K·∫æT QU·∫¢ X·∫æP H·∫†NG cho queries: {', '.join(queries)}")
        print("=" * 80)
        for i, (score, doc_idx) in enumerate(ranked[:15]):  # Hi·ªÉn th·ªã top 15
            relevance_mark = "‚≠ê" if scores[doc_idx] >= threshold else "  "
            print(f"{i+1:2d}. {score:.4f} {relevance_mark} - {documents[doc_idx][:120]}...")
            
        # Hi·ªÉn th·ªã th·ªëng k√™ scores
        scores_only = [score for score, _ in scores_rank]
        print(f"\nüìä TH·ªêNG K√ä SCORES:")
        print(f"Min: {min(scores_only):.4f}, Max: {max(scores_only):.4f}")
        print(f"Mean: {np.mean(scores_only):.4f}, Std: {np.std(scores_only):.4f}")
        print(f"Relevant docs (score ‚â• {threshold}): {sum(1 for s in scores if s >= threshold)}/{len(scores)}")
            
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()